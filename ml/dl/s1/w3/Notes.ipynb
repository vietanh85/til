{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow neural network\n",
    "\n",
    "## Neural network overview\n",
    "\n",
    "- Logistic regression: $(x, w, b) \\rightarrow z = w^{T}x +b \\rightarrow a = \\sigma(z) \\rightarrow \\mathcal{L}(a, y)$\n",
    "- Neural network is a stack of multiple of sigmoid units: $(x, W^{[1]}, b^{[1]}) \\rightarrow z^{[1]} = W^{[1]}x +b^{[1]} \\rightarrow a^{[1]} = \\sigma(z^{[1]}) \\rightarrow (x, W^{[2]}, b^{[2]}) \\rightarrow z^{[2]} = W^{[2]}x +b^{[2]} \\rightarrow a^{[2]} = \\sigma(z^{[2]}) \\rightarrow \\mathcal{L}(a^{[2]}, y)$\n",
    "- Backward computation to compute derivative: $da^{[2]} \\rightarrow dz^{[2]} \\rightarrow (dW^{[2]}, db^{[2]}) \\rightarrow da^{[1]} \\rightarrow dz^{[1]} \\rightarrow (dW^{[1]}, db^{[1]})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network representation (2 layers)\n",
    "\n",
    "Normally we will not count the first layer or input layer, the 3 layers neural network will include these following layers:\n",
    "\n",
    "- Input layer passs the input X to the hidden layer: \n",
    "$\n",
    "a^{[0]} = X = \\begin{bmatrix}\n",
    "    x_{1} \\\\\n",
    "    x_{2} \\\\\n",
    "    x_{3} \\\\\n",
    "    ... \\\\\n",
    "    x_{m} \\\\\n",
    "\\end{bmatrix}\n",
    "$ \n",
    "- Hidden layer: \n",
    "$\n",
    "a^{[1]} = \\begin{bmatrix}\n",
    "    a^{[1]}_{1} \\\\\n",
    "    a^{[1]}_{2} \\\\\n",
    "    a^{[1]}_{3} \\\\\n",
    "    ... \\\\\n",
    "    a^{[1]}_{n} \\\\\n",
    "\\end{bmatrix}\n",
    "$ \n",
    "associate with parameters \n",
    "$\n",
    "W^{[1]} = \\begin{bmatrix}\n",
    "    w^{[1]}_{11} & w^{[1]}_{12} ... & w^{[1]}_{1m}  \\\\\n",
    "    w^{[1]}_{21} & w^{[1]}_{22} ... & w^{[1]}_{2m}  \\\\\n",
    "    w^{[1]}_{31} & w^{[1]}_{32} ... & w^{[1]}_{3m}  \\\\\n",
    "    ... \\\\\n",
    "    w^{[1]}_{n1} & w^{[1]}_{n2} ... & w^{[1]}_{nm}  \\\\\n",
    "\\end{bmatrix}\n",
    "$ \n",
    "(n x m because we have n nodes in layer 1 and m nodes in the input layer) and\n",
    "$\n",
    "b^{[1]} = \\begin{bmatrix}\n",
    "    b^{[1]}_{1} \\\\\n",
    "    w^{[1]}_{2} \\\\\n",
    "    w^{[1]}_{3} \\\\\n",
    "    ... \\\\\n",
    "    w^{[1]}_{n} \\\\\n",
    "\\end{bmatrix}\n",
    "$ (n x 1).\n",
    "- Output layer: $a^{[2]} = \\hat{y}$ associate with parameters \n",
    "$\n",
    "W^{[2]} = \\begin{bmatrix}\n",
    "    w^{[2]}_{1} & w^{[2]}_{2} ... & w^{[2]}_{n} \n",
    "\\end{bmatrix}\n",
    "$ \n",
    "(1 x n because we have 1 node in the output layer and n nodes in the layer 2) and\n",
    "$\n",
    "b^{[2]} \n",
    "$ (1 x 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the neural network output\n",
    "\n",
    "### Computing the logistic regression output\n",
    "To compute the output of logistic regression we do 2 steps as follow:\n",
    "- Compute $z$ with a linear function: $z = w^Tx + b$\n",
    "- Compute activation $a$ as a sigmoid function of $z$: $a = \\sigma(z)$\n",
    "\n",
    "### Computing the neural network\n",
    "Computing the output of neural network is similar to the logistic regression but repeated for a lot of time\n",
    "- $Z^{[l]}_{i} = (W^{[l]}_i)^Tx + b^{[l]}_{i}$\n",
    "- $a^{[1]}_{i} = \\sigma(z^{[l]}_{i})$\n",
    "\n",
    "With $l$ is layer and $i$ is the node in layer\n",
    "\n",
    "**Vectorize**\n",
    "\n",
    "$\n",
    "Z^{[l]} = \n",
    "\\begin{bmatrix}\n",
    "    z^{[l]}_1 \\\\\n",
    "    z^{[l]}_2 \\\\\n",
    "    ... \\\\\n",
    "    z^{[l]}_n \\\\\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "    (w^{[l]}_1)^Tx + b^{[l]}_1\\\\\n",
    "    (w^{[l]}_2)^Tx + b^{[l]}_2\\\\\n",
    "    ... \\\\\n",
    "    (w^{[l]}_n)^Tx + b^{[l]}_n\\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "a^{[l]} = \n",
    "\\begin{bmatrix}\n",
    "    a^{[l]}_1 \\\\\n",
    "    a^{[l]}_2 \\\\\n",
    "    ... \\\\\n",
    "    a^{[l]}_n \\\\\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "    \\sigma(z^{[l]}_1) \\\\\n",
    "    \\sigma(z^{[l]}_2) \\\\\n",
    "    ... \\\\\n",
    "    \\sigma(z^{[l]}_n) \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "**Given input x, we have:**\n",
    "\n",
    "$z^{[1]} = W^{[1]}x + b^{[1]}$\n",
    "\n",
    "$a^{[1]} = \\sigma(z^{[1]})$\n",
    "\n",
    "$z^{[2]} = W^{[2]}a^{[1]} + b^{[2]}$\n",
    "\n",
    "$\\hat{y} = a^{[2]} = \\sigma(z^{[2]})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing across multiple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
