{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Strategy\n",
    "\n",
    "- Understand why Machine Learning strategy is important\n",
    "- Apply satisficing and optimizing metrics to set up your goal for ML projects\n",
    "- Choose a correct train/dev/test split of your dataset\n",
    "- Understand how to define human-level performance\n",
    "- Use human-level perform to define your key priorities in ML projects\n",
    "- Take the correct ML Strategic decision based on observations of performances and datase\n",
    "\n",
    "## Introduction to ML Strategy\n",
    "\n",
    "### Why ML Strategy\n",
    "\n",
    "There are a lot of options to try to improve ML system:\n",
    "- Collect more data\n",
    "- Collect more diverse training set\n",
    "- Train algorithm longer with gradient descent\n",
    "- Try Adam instead of gradient descent\n",
    "- Try bigger network\n",
    "- Try smaller network \n",
    "- Try dropout\n",
    "- Add $L_2$ regularization\n",
    "- Network architecture\n",
    "    - Activation function\n",
    "    - no. of hidden unit\n",
    "    - etc.\n",
    "\n",
    "If we choose wrongly or poorly, we can lost six months with nothing better.\n",
    "Need a quick and effective way to figure out which of these idea to pursue.\n",
    "\n",
    "### Orthogonalization\n",
    "\n",
    "**Chain of assumtions in ML**\n",
    "\n",
    "- Fit the training set well on cost function\n",
    "    - Bigger netwrok\n",
    "    - Adam\n",
    "- Fit the dev set well on cost function\n",
    "    - Regularization\n",
    "    - Bigger training set\n",
    "- Fit the test set well on cost function\n",
    "    - Bigger dev set\n",
    "- Perform well in real world\n",
    "    - Change dev set\n",
    "    - Change cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up your goal\n",
    "\n",
    "### Single number evaluation metric\n",
    "\n",
    "Need a single real number to evaluate classifiers\n",
    "\n",
    "### Satisficing and Optimizing metric\n",
    "\n",
    "$cost = accuracy - 0.5 \\times runningTime$\n",
    "\n",
    "$\\rightarrow$ miximizing accuracy, subject to running time less than or equa 100ms.\n",
    "- Optimizing metric: Accuracy\n",
    "- Satisficing metric: Running time (threshold)\n",
    "\n",
    "If we have N metrics:\n",
    "- pick 1 metric to be the optimizing metric\n",
    "- N - 1 metrics to be satisficing metrics\n",
    "\n",
    "**For example:**\n",
    "\n",
    "Wake words/Trigger words:\n",
    "\n",
    "Alexa, OK Google, Hey Siri, Nihao Baidu.\n",
    "\n",
    "- accuracy\n",
    "- number of false positive\n",
    "\n",
    "$\\rightarrow$ maximize accuracy, s.t. less than 1 false positive every 24h.\n",
    "\n",
    "### Train/dev/test distributions\n",
    "\n",
    "- Dev and test set should come from same distribution\n",
    "- Randomly shuffle data to dev and test set\n",
    "\n",
    "Choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on.\n",
    "\n",
    "### Size of the dev and test sets\n",
    "- Big data, the rule of 70/20/10 or 60/30/10 should be 99/0.5/0.5\n",
    "- Size of the test set need to big enough to give confident in the overall performance of the system\n",
    "    - Test set used in development should be called dev set\n",
    "\n",
    "### When to change dev/test sets and metrics\n",
    "\n",
    "Error: $\\frac{1}{m_{dev}} \\sum_{i=1}^{m_{dev}} \\mathcal{L}\\{y^{(i)}_{pred} \\ne y^{(i)}\\}$\n",
    "\n",
    "The problem with this metric is that it will treat the unexpected inputs such as pornographic that has been misclassifed as a cat the same with a bird picture. This called the rank preference problem.\n",
    "\n",
    "Way to deal with that is to add a weight that:\n",
    "\n",
    "- $w^{(i)} = 1$ if $x^{(i)}$ is non-porn\n",
    "- $w^{(i)} = 10$ if $x^{(i)}$ is porn\n",
    "\n",
    "Weighted error: $\\frac{1}{\\sum w^{(i)}} \\sum_{i=1}^{m_{dev}} w^{(i)} \\mathcal{L}\\{y^{(i)}_{pred} \\ne y^{(i)}\\}$\n",
    "\n",
    "Add weight to the cost funtion J for the inputs:\n",
    "\n",
    "$J = \\frac{1}{\\sum w^{(i)}} \\sum_{i=1}^{m} w^{(i)} \\mathcal{L}\\{\\hat(y^{(i)}), y^{(i)}\\}$\n",
    "\n",
    "If the algorithm run good ion dev/test set but bad in real world, need to change the dev/test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing to human-level performance\n",
    "\n",
    "### Why human-level performance?\n",
    "\n",
    "Humans are quite good at a lot of tasks. As long as ML is worse than humans, we can:\n",
    "- Get labeled data from humans\n",
    "- Gain insight from manual error analysis: Why did a person get this right?\n",
    "- Better analysis of bias/variance\n",
    "\n",
    "### Avoidable bias\n",
    "\n",
    "Error | Set A | Set B\n",
    "--- | --- | ---\n",
    " **Human** $(\\approx Bayes)$| 1% | 7.5%\n",
    "**Training error** | 8% | 8%\n",
    "**Dev error** | 10% | 10%\n",
    "**Focus** | **Bias** | **Variance**\n",
    "\n",
    "$\n",
    "Avoidable \\ bias = training \\ error - human \\ error\\\\\n",
    "Variance = training \\ error - dev \\ error\n",
    "$\n",
    "\n",
    "### Understanding human-level performance\n",
    "\n",
    "It's often harder to determine to focus on bias or variance when approaching human-level error\n",
    "\n",
    "### Surpassing human-level performance\n",
    "\n",
    "Problem where ML significantly surpasses human-level performance:\n",
    "- Online advertising\n",
    "- Product recommendations\n",
    "- Logistic (predicting transit time)\n",
    "- Load approvals\n",
    "\n",
    "All of them are **structured-data** and **not nature perception problems**, **lots of data**\n",
    "\n",
    "Some nature perception problems that ML can surpass human:\n",
    "\n",
    "- Speech recognition \n",
    "- Some image recognition\n",
    "- Medical tasks\n",
    "    - ECG, skin cancer, etc.\n",
    "    \n",
    "### Improving your model performance\n",
    "\n",
    "Assumptions of supervied learning:\n",
    "- Fit the training set pretty well -> low avaidable bias\n",
    "- Generalize pretty well for dev/test set -> low variance\n",
    "\n",
    "To reduce avoidable bias:\n",
    "- Train bigget model\n",
    "- Train longer/better optimization algoritms (momentum, RMSprop, Adam)\n",
    "- NN architecture/hyperparameters search (CNN, RNN)\n",
    "\n",
    "To reduce variance:\n",
    "- More data\n",
    "- Regularization (L2, dropout, data argumentation)\n",
    "- NN architecture/hyperparameters search (CNN, RNN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
